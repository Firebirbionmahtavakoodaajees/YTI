# ğŸï¸ YTI Autonomous Driving AI â€” The Best YTI Project in the World ğŸŒ

Welcome to **YTI Autonomous Driving AI**, the ultimate end-to-end self-driving simulation project.  
This system watches your gameplay, learns from your inputs, and then drives *just like you* â€” or better.

---

## ğŸš€ Project Overview

This repository contains a full pipeline for:
- Capturing your screen and driving inputs
- Building datasets automatically
- Training a deep Convolutional Neural Network (CNN)
- Deploying that trained model for autonomous control

Everything you need to create your own AI driver â€” neatly packaged and beautifully coded.

---

## ğŸ§  Features

- ğŸ¥ **Live Frame Capture** â€” Records gameplay at 25 FPS and resizes to 320Ã—240.  
- âŒ¨ï¸ **Input Logging** â€” Captures `W`, `A`, `S`, `D`, `Space`, and `R` keys in real-time.  
- ğŸ§© **Automated Dataset Creation** â€” Saves frames + inputs into `.pkl` files every 100 samples.  
- ğŸ§® **Custom CNN Model** â€” Learns steering, throttle, braking, resetting, and handbrake.  
- âš¡ **GPU Acceleration** â€” Automatically detects and utilizes CUDA for training.  
- ğŸ’¾ **Checkpoint System** â€” Saves model weights every 5 epochs for safety and recovery.  

---

## ğŸ“‚ Folder Structure


---

## ğŸ§± Model Architecture

| Layer | Type        | Kernel | Stride | Padding | Channels | Notes |
|:------|:-------------|:-------:|:-------:|:--------:|:----------:|:------|
| 1 | Conv2d | 5Ã—5 | 1 | 2 | 15 â†’ 32 | Broad feature extraction |
| 2 | Conv2d | 3Ã—3 | 2 | 1 | 32 â†’ 64 | Local feature refinement |
| 3 | Conv2d | 3Ã—3 | 2 | 1 | 64 â†’ 128 | Object edge detection |
| 4 | Conv2d | 3Ã—3 | 2 | 1 | 128 â†’ 256 | Scene compression |
| 5 | Fully Connected | â€” | â€” | â€” | 256 â†’ 5 | Output predictions |

**Outputs:** `[steer, throttle, brake, reset, handbrake]`

---

## âš™ï¸ How to Use

### 1ï¸âƒ£ Record Data
Run:
```bash
python framegrab.py
Then drive using your normal controls.
```
Every 100 frames, the data will automatically save into ğŸ“‚trainingData.

### 2ï¸âƒ£ Train the Model

Run:

```bash
python traincnn.py
```

- Detects your GPU automatically
- Trains using Mean Squared Error (MSE) loss
- Saves checkpoints in /models/ every 5 epochs

### 3ï¸âƒ£ Drive with AI

After training, load the model and connect it to your input system â€”
the AI will replicate your driving behavior frame-by-frame.
```bash
python drivingAI.py
```
---

## ğŸ“ˆ Recommended Settings
| Parameter          | Recommended Value | Description                               |
| :----------------- | :---------------: | :---------------------------------------- |
| `epochs`           |       50â€“100      | More = better learning (if data is large) |
| `batch_size`       |       32â€“256      | 64 recommended for strong GPUs            |
| `learning_rate`    |       0.001       | Stable for Adam optimizer                 |
| `input_resolution` |      320Ã—240      | Great balance between speed and detail    |

---
## ğŸ§° Requirements
Install required libraries:
```Bash
pip install torch torchvision tqdm mss pillow pynput numpy
```
Optional (for advanced logging) *(Not implemented yet)*:
```Bash
pip install matplotlib seaborn tensorboard
```
---

## ğŸ”® Future Plans

- ğŸ§­ Real-time inference with keyboard/mouse output
- ğŸ® Integration with popular simulators (BeamNG, GTA, Assetto Corsa) (Technically already done)
- ğŸ“Š Training dashboard & visualizations
- ğŸ¤– Adaptive reinforcement learning mode

---

## ğŸ’¬ Notes

- The model uses 5 consecutive frames as temporal input to understand motion.
- Outputs are normalized between:
- Steering: -1 â†’ 1
- Throttle/Brake/Reset/Handbrake: 0 â†’ 1
- Designed to train even on mid-range GPUs efficiently.

---

## ğŸ Credits

Developed with passion, precision, and a little too much coffee â˜•
by the YTI team â€” creators of The Best YTI Project in the World.

---

## ğŸªª License

This project is licensed under the MIT License â€” free for all to use, modify, and build upon.

---


# ğŸŒŸ Star the repo

## Letâ€™s make AI driving fun, fast, and free for everyone!

---
